{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG_16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yanli499/APS360-Project/blob/Lucy_1/VGG_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48t6NUyZ_hqq",
        "colab_type": "text"
      },
      "source": [
        "YLL Test Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dwEF8nz--KU",
        "colab_type": "code",
        "outputId": "99d58881-193a-4c65-8fd6-8db6c7a1f97e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# import os\n",
        "# import time\n",
        "# import torch.nn.functional as F\n",
        "# import torch.optim as optim\n",
        "# import torchvision.transforms as transforms\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from torchvision import datasets, transforms\n",
        "# from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "\n",
        "# get vgg16 model\n",
        "vgg16 = torchvision.models.vgg16(pretrained=True)\n",
        "\n",
        "vgg16.features\n",
        "vgg16.classifier"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:07<00:00, 76.4MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "  (1): ReLU(inplace=True)\n",
              "  (2): Dropout(p=0.5, inplace=False)\n",
              "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (4): ReLU(inplace=True)\n",
              "  (5): Dropout(p=0.5, inplace=False)\n",
              "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bCJlYni8kel",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "87028b8f-9596-4c48-a187-e7a0157e0322"
      },
      "source": [
        "\"\"\"\n",
        "The VGG-16 is able to classify 1000 different labels; we just need 4 instead.\n",
        "In order to do that we are going replace the last fully connected layer of the \n",
        "model with a new one with 4 output features instead of 1000.\n",
        "\n",
        "In PyTorch, we can access the VGG-16 classifier with model.classifier, \n",
        "which is an 6-layer array. We will replace the last entry.\n",
        "\"\"\"\n",
        "# from https://www.kaggle.com/carloalbertobarbano/vgg16-transfer-learning-pytorch\n",
        "num_features = vgg16.classifier[6].in_features\n",
        "features = list(vgg16.classifier.children())[:-1] # Remove last layer\n",
        "features.extend([nn.Linear(num_features, len(class_names))]) # Add our layer with 4 outputs\n",
        "vgg16.classifier = nn.Sequential(*features) # Replace the model classifier"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-75fe32b64f7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnum_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Remove last layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Add our layer with 4 outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Replace the model classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'class_names' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z5xq0l0_467",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get + clean up some data\n",
        "from PIL import Image\n",
        "img = Image.open('C:/Python27/image.bmp')\n",
        "new_img = img.resize((224, 224)) # for input into feature layer\n",
        "new_img.save( 'C:/Python27/image.png', 'png')\n",
        "\n",
        "img = Image.open('image.png').convert('LA')\n",
        "img.save('greyscale.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt8z2ig7AFYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# feed image to model\n",
        "x = \"some img\"\n",
        "x = x.reshape([1, 3, 350, 210]) # add a dimension for batching\n",
        "print(x.shape)\n",
        "features = vgg16.features(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frRAYSOZGQ9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# AlexNet Implementation\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# alexnet\n",
        "import torchvision.models\n",
        "\n",
        "torch.manual_seed(1) # set the random seed\n",
        "\n",
        "\n",
        "# obtain one batch of training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# confirm output from AlexNet feature extraction\n",
        "alexNet = torchvision.models.alexnet(pretrained=True)\n",
        "features = alexNet.features(images)\n",
        "features.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keCDm37IGGIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mount our Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOkjHuzpGCs_",
        "colab_type": "text"
      },
      "source": [
        "YLL: Random code, potentially useful"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHz0DgU4Czqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# From: https://www.kaggle.com/carloalbertobarbano/vgg16-transfer-learning-pytorch\n",
        "def train_model(vgg, criterion, optimizer, scheduler, num_epochs=10):\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(vgg.state_dict())\n",
        "    best_acc = 0.0\n",
        "    \n",
        "    avg_loss = 0\n",
        "    avg_acc = 0\n",
        "    avg_loss_val = 0\n",
        "    avg_acc_val = 0\n",
        "    \n",
        "    train_batches = len(dataloaders[TRAIN])\n",
        "    val_batches = len(dataloaders[VAL])\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"Epoch {}/{}\".format(epoch, num_epochs))\n",
        "        print('-' * 10)\n",
        "        \n",
        "        loss_train = 0\n",
        "        loss_val = 0\n",
        "        acc_train = 0\n",
        "        acc_val = 0\n",
        "        \n",
        "        vgg.train(True)\n",
        "        \n",
        "        for i, data in enumerate(dataloaders[TRAIN]):\n",
        "            if i % 100 == 0:\n",
        "                print(\"\\rTraining batch {}/{}\".format(i, train_batches / 2), end='', flush=True)\n",
        "                \n",
        "            # Use half training dataset\n",
        "            if i >= train_batches / 2:\n",
        "                break\n",
        "                \n",
        "            inputs, labels = data\n",
        "            \n",
        "            if use_gpu:\n",
        "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
        "            else:\n",
        "                inputs, labels = Variable(inputs), Variable(labels)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            outputs = vgg(inputs)\n",
        "            \n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            loss_train += loss.data[0]\n",
        "            acc_train += torch.sum(preds == labels.data)\n",
        "            \n",
        "            del inputs, labels, outputs, preds\n",
        "            torch.cuda.empty_cache()\n",
        "        \n",
        "        print()\n",
        "        # * 2 as we only used half of the dataset\n",
        "        avg_loss = loss_train * 2 / dataset_sizes[TRAIN]\n",
        "        avg_acc = acc_train * 2 / dataset_sizes[TRAIN]\n",
        "        \n",
        "        vgg.train(False)\n",
        "        vgg.eval()\n",
        "            \n",
        "        for i, data in enumerate(dataloaders[VAL]):\n",
        "            if i % 100 == 0:\n",
        "                print(\"\\rValidation batch {}/{}\".format(i, val_batches), end='', flush=True)\n",
        "                \n",
        "            inputs, labels = data\n",
        "            \n",
        "            if use_gpu:\n",
        "                inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n",
        "            else:\n",
        "                inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            outputs = vgg(inputs)\n",
        "            \n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            loss_val += loss.data[0]\n",
        "            acc_val += torch.sum(preds == labels.data)\n",
        "            \n",
        "            del inputs, labels, outputs, preds\n",
        "            torch.cuda.empty_cache()\n",
        "        \n",
        "        avg_loss_val = loss_val / dataset_sizes[VAL]\n",
        "        avg_acc_val = acc_val / dataset_sizes[VAL]\n",
        "        \n",
        "        print()\n",
        "        print(\"Epoch {} result: \".format(epoch))\n",
        "        print(\"Avg loss (train): {:.4f}\".format(avg_loss))\n",
        "        print(\"Avg acc (train): {:.4f}\".format(avg_acc))\n",
        "        print(\"Avg loss (val): {:.4f}\".format(avg_loss_val))\n",
        "        print(\"Avg acc (val): {:.4f}\".format(avg_acc_val))\n",
        "        print('-' * 10)\n",
        "        print()\n",
        "        \n",
        "        if avg_acc_val > best_acc:\n",
        "            best_acc = avg_acc_val\n",
        "            best_model_wts = copy.deepcopy(vgg.state_dict())\n",
        "        \n",
        "    elapsed_time = time.time() - since\n",
        "    print()\n",
        "    print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
        "    print(\"Best acc: {:.4f}\".format(best_acc))\n",
        "    \n",
        "    vgg.load_state_dict(best_model_wts)\n",
        "    return vgg"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}