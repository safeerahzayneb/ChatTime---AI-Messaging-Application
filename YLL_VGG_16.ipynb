{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YLL_VGG_16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yanli499/APS360-Project/blob/Lucy_1/YLL_VGG_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48t6NUyZ_hqq",
        "colab_type": "text"
      },
      "source": [
        "YLL Test Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLljEYqZAWVz",
        "colab_type": "code",
        "outputId": "0f5223f3-2a50-49d7-9799-8ba1b25b7243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# NEVER RUN THIS AGAIN!!!\n",
        "\n",
        "# logic for sorting thru photos for the ones we want\n",
        "#only run this code once \n",
        "\"\"\"\n",
        "- eg file name: AF01ANFL.JPG\n",
        "- Check:\n",
        "    - length of name = 7, for straight profile only\n",
        "    - str[4:5] = {\"AF\":\"afraid\", \"AN\":\"angry\", \"DI\":\"disgusted\", \"HA\":\"happy\",\n",
        "    \"NE\":\"neutral\", \"SA\":sad\", \"SU\":\"surprised\"}\n",
        "\"\"\"\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# mount our Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# classes are folders in each directory with these names\n",
        "classes = ['afraid','angry','disgusted','happy','neutral','sad','surprised']\n",
        "\n",
        "\n",
        "emotion_code = {\"AF\":\"afraid\", \"AN\":\"angry\", \"DI\":\"disgusted\", \"HA\":\"happy\", \n",
        "                \"NE\":\"neutral\", \"SA\":\"sad\", \"SU\":\"surprised\"}\n",
        "\n",
        "data_dir='/content/drive/My Drive/Colab Notebooks/Faces'\n",
        "\n",
        "# delete existing folder\n",
        "if os.path.exists(data_dir+'/'):\n",
        "    shutil.rmtree(data_dir+'/')\n",
        "\n",
        "try:\n",
        "    os.mkdir(data_dir)\n",
        "\n",
        "    for i in range(len(classes)):\n",
        "        os.mkdir(data_dir+'/'+classes[i])\n",
        "\n",
        "    os.mkdir(data_dir+'/train')\n",
        "    for i in range(len(classes)):\n",
        "        os.mkdir(data_dir+'/train/'+classes[i])\n",
        "    \n",
        "    os.mkdir(data_dir+'/val')\n",
        "    for i in range(len(classes)):\n",
        "        os.mkdir(data_dir+'/val/'+classes[i])\n",
        "\n",
        "    os.mkdir(data_dir+'/test')\n",
        "    for i in range(len(classes)):\n",
        "        os.mkdir(data_dir+'/test/'+classes[i])\n",
        "\n",
        "except OSError:\n",
        "    print (\"Creation of the directories failed!\")\n",
        "else:\n",
        "    print (\"Successfully created the directories!\")\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "# rootdir = path to KDEF main folder\n",
        "rootdir = '/content/drive/My Drive/Colab Notebooks/PROJECT/KDEF/'\n",
        "for subdir, dirs, files in os.walk(rootdir):\n",
        "    for file in files:\n",
        "        filename = subdir + os.sep + file\n",
        "        if file.endswith(\"S.jpg\") or file.endswith(\"S.JPG\"): \n",
        "            # now crop and modify each image \n",
        "            # get + clean up some data\n",
        "            img = Image.open(filename).convert('L')\n",
        "            new_img = img.resize((224, 224)) # for input into feature layer\n",
        "            if (file[4:6] == \"AF\"): \n",
        "                # Move a file from the directory directory1 to directory2\n",
        "                #shutil.move(directory+filename, data_dir+'/'+emotion_code[\"AF\"]+'/'+filename)\n",
        "                new_img.save(data_dir+'/'+emotion_code[\"AF\"]+'/'+file)\n",
        "            elif (file[4:6] == \"AN\"): \n",
        "                # Move a file from the directory directory1 to directory2\n",
        "                #shutil.move(directory+filename, data_dir+'/'+emotion_code[\"AN\"]+'/'+filename)\n",
        "                new_img.save(data_dir+'/'+emotion_code[\"AN\"]+'/'+file)\n",
        "            elif (file[4:6] == \"DI\"): \n",
        "                # Move a file from the directory directory1 to directory2\n",
        "                #shutil.move(directory+filename, data_dir+'/'+emotion_code[\"DI\"]+'/'+filename)\n",
        "                new_img.save(data_dir+'/'+emotion_code[\"DI\"]+'/'+file)\n",
        "            elif (file[4:6] == \"HA\"): \n",
        "                # Move a file from the directory directory1 to directory2\n",
        "                #shutil.move(directory+filename, data_dir+'/'+emotion_code[\"HA\"]+'/'+filename)\n",
        "                new_img.save(data_dir+'/'+emotion_code[\"HA\"]+'/'+file)\n",
        "            elif (file[4:6] == \"NE\"):\n",
        "                # Move a file from the directory directory1 to directory2\n",
        "                #shutil.move(directory+filename, data_dir+'/'+emotion_code[\"NE\"]+'/'+filename)\n",
        "                new_img.save(data_dir+'/'+emotion_code[\"NE\"]+'/'+file)\n",
        "            elif (file[4:6] == \"SA\"): \n",
        "                # Move a file from the directory directory1 to directory2\n",
        "                #shutil.move(directory+filename, data_dir+'/'+emotion_code[\"SA\"]+'/'+filename)\n",
        "                new_img.save(data_dir+'/'+emotion_code[\"SA\"]+'/'+file)\n",
        "            elif (file[4:6] == \"SU\"): \n",
        "                # Move a file from the directory directory1 to directory2\n",
        "                #shutil.move(directory+filename, data_dir+'/'+emotion_code[\"SU\"]+'/'+filename)\n",
        "                new_img.save(data_dir+'/'+emotion_code[\"SU\"]+'/'+file)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# don't know how :(\n",
        "# use shutil.move(data_dir+'/'+emotion_code[\"SU\"]+'/'+filename, \n",
        "#                   data_dir+'/train/'+emotion_code[\"SU\"]+'/'+filename)\n",
        "# use some sort of iterator\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Successfully created the directories!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ONtGEPi4oIH",
        "colab_type": "code",
        "outputId": "b7700ba0-6876-4654-f4c1-41565465d0ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# now do train test split (60:20:20)\n",
        "# each class = 140 images --> 84 train, 28 val, 28 test\n",
        "import random\n",
        "\n",
        "# mount our Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# classes are folders in each directory with these names\n",
        "classes = ['afraid','angry','disgusted','happy','neutral','sad','surprised']\n",
        "\n",
        "data_dir='/content/drive/My Drive/Colab Notebooks/Faces'\n",
        "\n",
        "# divide data into train, val, + test\n",
        "for c in classes:\n",
        "    filepath = data_dir+'/'+c\n",
        "    names = []\n",
        "\n",
        "    for file in os.listdir(filepath):\n",
        "        names.append(file)\n",
        "    random.shuffle(names)\n",
        "\n",
        "    count = 0\n",
        "    for name in names:\n",
        "        if(count == 84):\n",
        "            break\n",
        "        else:\n",
        "            shutil.move(filepath+'/'+name, data_dir+'/train/'+c+'/'+name)\n",
        "            names.remove(name)\n",
        "            count += 1\n",
        "\n",
        "    count = 0\n",
        "    for name in names:\n",
        "        if(count == 28):\n",
        "            break\n",
        "        else:\n",
        "            shutil.move(filepath+'/'+name, data_dir+'/val/'+c+'/'+name)\n",
        "            names.remove(name)\n",
        "            count += 1\n",
        "\n",
        "    count = 0\n",
        "    for name in names:\n",
        "        if(count == 28):\n",
        "            break\n",
        "        else:\n",
        "            shutil.move(filepath+'/'+name, data_dir+'/test/'+c+'/'+name)\n",
        "            names.remove(name)\n",
        "            count += 1\n",
        "\n",
        "\n",
        "\n",
        "# define training and test data directories\n",
        "# train_dir = os.path.join(data_dir, '/train/')\n",
        "# val_dir = os.path.join(data_dir, '/val/')\n",
        "# test_dir = os.path.join(data_dir, '/test/')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ahe2CDJFzyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Loading\n",
        "def get_data_loader(data_dir, batch_size):\n",
        "  \n",
        "    # mount our Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # define training and test data directories\n",
        "    train_dir = os.path.join(data_dir, 'train/')\n",
        "    val_dir = os.path.join(data_dir, 'val/')\n",
        "    test_dir = os.path.join(data_dir, 'test/')\n",
        "\n",
        "    # classes are folders in each directory with these names\n",
        "    classes = ['afraid','angry','disgusted','happy','neutral','sad','surprised']\n",
        "\n",
        "\n",
        "    # resize all images to 224 x 224\n",
        "    data_transform = transforms.Compose([transforms.CenterCrop(224), \n",
        "                                      transforms.ToTensor()])\n",
        "\n",
        "    train_data = datasets.ImageFolder(train_dir, transform=data_transform)\n",
        "    val_data = datasets.ImageFolder(val_dir, transform=data_transform)\n",
        "    test_data = datasets.ImageFolder(test_dir, transform=data_transform)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
        "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
        "    \n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "# Training\n",
        "def get_model_name(batch_size, learning_rate, epoch, name=\"VGG\"):\n",
        "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object containing the hyperparameters\n",
        "    Returns:\n",
        "        path: A string with the hyperparameter name and value concatenated\n",
        "    \"\"\"\n",
        "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
        "                                                   batch_size,\n",
        "                                                   learning_rate,\n",
        "                                                   epoch)\n",
        "    return path\n",
        "  \n",
        "def get_accuracy(model, loader):\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for imgs, labels in loader:\n",
        "        \n",
        "        #############################################\n",
        "        #To Enable GPU Usage\n",
        "        # if torch.cuda.is_available():\n",
        "        #     imgs = imgs.cuda()\n",
        "        #     labels = labels.cuda()\n",
        "        #############################################\n",
        "        \n",
        "        output = model(imgs)\n",
        "        \n",
        "        #select index with maximum prediction score\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "        \n",
        "    return correct / total\n",
        "\n",
        "def evaluate(net, loader, criterion):\n",
        "    \"\"\" Evaluate the network on the validation set.\n",
        "\n",
        "     Args:\n",
        "         net: PyTorch neural network object\n",
        "         loader: PyTorch data loader for the validation set\n",
        "         criterion: The loss function\n",
        "     Returns:\n",
        "         acc: A scalar for the avg classification acc over the validation set\n",
        "         loss: A scalar for the average loss function over the validation set\n",
        "     \"\"\"\n",
        "    total_loss = 0.0\n",
        "    total_epoch = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, data in enumerate(loader, 0):\n",
        "        inputs, labels = data\n",
        "        \n",
        "        #############################################\n",
        "        #To Enable GPU Usage\n",
        "        # if torch.cuda.is_available():\n",
        "        #     inputs = inputs.cuda()\n",
        "        #     labels = labels.cuda()\n",
        "        #############################################\n",
        "        \n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        #select index with maximum prediction score\n",
        "        pred = outputs.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += inputs.shape[0]\n",
        "        \n",
        "        total_loss += loss\n",
        "        total_epoch += len(labels)\n",
        "    \n",
        "    acc = correct / total\n",
        "    loss = float(total_loss) / (i + 1)\n",
        "    \n",
        "    return acc, loss\n",
        "\n",
        "# Training Curve\n",
        "def plot_training_curve(path):\n",
        "    \"\"\" Plots the training curve for a model run, given the csv files\n",
        "    containing the train/validation accuracy/loss.\n",
        "\n",
        "    Args:\n",
        "        path: The base path of the csv files produced during training\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    train_acc = np.loadtxt(\"{}_train_acc.csv\".format(path))\n",
        "    val_acc = np.loadtxt(\"{}_val_acc.csv\".format(path))\n",
        "    train_loss = np.loadtxt(\"{}_train_loss.csv\".format(path))\n",
        "    val_loss = np.loadtxt(\"{}_val_loss.csv\".format(path))\n",
        "    \n",
        "    n = len(train_acc) # number of epochs\n",
        "    \n",
        "    plt.title(\"Train vs Validation Loss\")\n",
        "    plt.plot(range(1,n+1), train_loss, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_loss, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "    \n",
        "    plt.title(\"Train vs Validation Accuracy\")\n",
        "    plt.plot(range(1,n+1), train_acc, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
        "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
        "\n",
        "    \n",
        "def train_net(net, batch_size=64, learning_rate=0.01, num_epochs=30,\n",
        "    data_dir='/content/drive/My Drive/Colab Notebooks/Faces/'):\n",
        "\n",
        "    # Fixed PyTorch random seed for reproducible result\n",
        "    torch.manual_seed(1000)\n",
        "    \n",
        "    # Obtain the PyTorch data loader objects to load batches of the datasets\n",
        "    train_loader, val_loader, test_loader = get_data_loader(data_dir, batch_size)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "    \n",
        "    # Set up some numpy arrays to store the training/test loss/erruracy\n",
        "    train_acc = np.zeros(num_epochs)\n",
        "    train_loss = np.zeros(num_epochs)\n",
        "    val_acc = np.zeros(num_epochs)\n",
        "    val_loss = np.zeros(num_epochs)\n",
        "    \n",
        "    # Train the network\n",
        "    # Loop over the data iterator and sample a new batch of training data\n",
        "    # Get the output from the network, and optimize our loss function.\n",
        "    \n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "        total_train_loss = 0.0\n",
        "        total_train_acc = 0.0\n",
        "        total_epoch = 0\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            \n",
        "            # Get the inputs\n",
        "            imgs, labels = data\n",
        "            \n",
        "            #############################################\n",
        "            #To Enable GPU Usage\n",
        "            # if torch.cuda.is_available():\n",
        "            #     imgs = imgs.cuda()\n",
        "            #     labels = labels.cuda()\n",
        "            #############################################\n",
        "            \n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass, backward pass, and optimize\n",
        "            outputs = net(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            total_train_loss += loss\n",
        "            total_epoch += len(labels)\n",
        "        train_acc[epoch] = get_accuracy(net, train_loader)\n",
        "        train_loss[epoch] = float(total_train_loss) / (i+1)\n",
        "        val_acc[epoch], val_loss[epoch] = evaluate(net, val_loader, criterion)\n",
        "        \n",
        "        print((\"Epoch {}: Train acc: {}, Train loss: {} |\"+\n",
        "               \"Validation acc: {}, Validation loss: {}\").format(\n",
        "                   epoch + 1,\n",
        "                   train_acc[epoch],\n",
        "                   train_loss[epoch],\n",
        "                   val_acc[epoch],\n",
        "                   val_loss[epoch]))\n",
        "        \n",
        "        # Save the current model (checkpoint) to a file\n",
        "        model_path = get_model_name(net.name, batch_size, learning_rate, epoch)\n",
        "        torch.save(net.state_dict(), model_path)\n",
        "    \n",
        "    print('Finished Training')\n",
        "    \n",
        "    # Write the train/test loss/accuracy into CSV file for plotting later\n",
        "    epochs = np.arange(1, num_epochs + 1)\n",
        "    np.savetxt(\"{}_train_acc.csv\".format(model_path), train_acc)\n",
        "    np.savetxt(\"{}_train_loss.csv\".format(model_path), train_loss)\n",
        "    np.savetxt(\"{}_val_acc.csv\".format(model_path), val_acc)\n",
        "    np.savetxt(\"{}_val_loss.csv\".format(model_path), val_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dwEF8nz--KU",
        "colab_type": "code",
        "outputId": "0d721750-2a0b-499e-c867-a591aeed1e16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.models\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "classes = ['afraid','angry','disgusted','happy','neutral','sad','surprised']\n",
        "data_dir='/content/drive/My Drive/Colab Notebooks/Faces'\n",
        "\n",
        "# get vgg16 model\n",
        "vgg16 = torchvision.models.vgg16(pretrained=True)\n",
        "\n",
        "# from https://www.kaggle.com/carloalbertobarbano/vgg16-transfer-learning-pytorch\n",
        "classes = ['afraid','angry','disgusted','happy','neutral','sad','surprised']\n",
        "\n",
        "# num_features = vgg16.classifier[6].in_features\n",
        "# features = list(vgg16.classifier.children())[:-1] # Remove last layer\n",
        "# features.extend([nn.Linear(num_features, len(classes))]) # Add our layer with 7 outputs\n",
        "# vgg16.classifier = nn.Sequential(*features) # Replace the model classifier\n",
        "\n",
        "# if torch.cuda.is_available():\n",
        "#     classifier.cuda()\n",
        "    \n",
        "train_net(vgg16.classifier, learning_rate = 0.001, batch_size=512, num_epochs=20, data_dir=data_dir)\n",
        "\n",
        "model_path = get_model_name(batch_size=512, learning_rate=0.001, epoch=19)\n",
        "plot_training_curve('/content/' + model_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "  (1): ReLU(inplace=True)\n",
              "  (2): Dropout(p=0.5, inplace=False)\n",
              "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (4): ReLU(inplace=True)\n",
              "  (5): Dropout(p=0.5, inplace=False)\n",
              "  (6): Linear(in_features=4096, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bCJlYni8kel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "NOTE:\n",
        "The VGG-16 is able to classify 1000 different labels; we just need 4 instead.\n",
        "In order to do that we are going replace the last fully connected layer of the \n",
        "model with a new one with 4 output features instead of 1000.\n",
        "\n",
        "In PyTorch, we can access the VGG-16 classifier with model.classifier, \n",
        "which is an 6-layer array. We will replace the last entry.\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt8z2ig7AFYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# feed image to model\n",
        "x = \"some img\"\n",
        "x = x.reshape([1, 3, 350, 210]) # add a dimension for batching\n",
        "print(x.shape)\n",
        "features = vgg16.features(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHz0DgU4Czqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# From: https://www.kaggle.com/carloalbertobarbano/vgg16-transfer-learning-pytorch\n",
        "def train_model(vgg, criterion, optimizer, scheduler, num_epochs=10):\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(vgg.state_dict())\n",
        "    best_acc = 0.0\n",
        "    \n",
        "    avg_loss = 0\n",
        "    avg_acc = 0\n",
        "    avg_loss_val = 0\n",
        "    avg_acc_val = 0\n",
        "    \n",
        "    train_batches = len(dataloaders[TRAIN])\n",
        "    val_batches = len(dataloaders[VAL])\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"Epoch {}/{}\".format(epoch, num_epochs))\n",
        "        print('-' * 10)\n",
        "        \n",
        "        loss_train = 0\n",
        "        loss_val = 0\n",
        "        acc_train = 0\n",
        "        acc_val = 0\n",
        "        \n",
        "        vgg.train(True)\n",
        "        \n",
        "        for i, data in enumerate(dataloaders[TRAIN]):\n",
        "            if i % 100 == 0:\n",
        "                print(\"\\rTraining batch {}/{}\".format(i, train_batches / 2), end='', flush=True)\n",
        "                \n",
        "            # Use half training dataset\n",
        "            if i >= train_batches / 2:\n",
        "                break\n",
        "                \n",
        "            inputs, labels = data\n",
        "            \n",
        "            if use_gpu:\n",
        "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
        "            else:\n",
        "                inputs, labels = Variable(inputs), Variable(labels)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            outputs = vgg(inputs)\n",
        "            \n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            loss_train += loss.data[0]\n",
        "            acc_train += torch.sum(preds == labels.data)\n",
        "            \n",
        "            del inputs, labels, outputs, preds\n",
        "            torch.cuda.empty_cache()\n",
        "        \n",
        "        print()\n",
        "        # * 2 as we only used half of the dataset\n",
        "        avg_loss = loss_train * 2 / dataset_sizes[TRAIN]\n",
        "        avg_acc = acc_train * 2 / dataset_sizes[TRAIN]\n",
        "        \n",
        "        vgg.train(False)\n",
        "        vgg.eval()\n",
        "            \n",
        "        for i, data in enumerate(dataloaders[VAL]):\n",
        "            if i % 100 == 0:\n",
        "                print(\"\\rValidation batch {}/{}\".format(i, val_batches), end='', flush=True)\n",
        "                \n",
        "            inputs, labels = data\n",
        "            \n",
        "            if use_gpu:\n",
        "                inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n",
        "            else:\n",
        "                inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            outputs = vgg(inputs)\n",
        "            \n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            loss_val += loss.data[0]\n",
        "            acc_val += torch.sum(preds == labels.data)\n",
        "            \n",
        "            del inputs, labels, outputs, preds\n",
        "            torch.cuda.empty_cache()\n",
        "        \n",
        "        avg_loss_val = loss_val / dataset_sizes[VAL]\n",
        "        avg_acc_val = acc_val / dataset_sizes[VAL]\n",
        "        \n",
        "        print()\n",
        "        print(\"Epoch {} result: \".format(epoch))\n",
        "        print(\"Avg loss (train): {:.4f}\".format(avg_loss))\n",
        "        print(\"Avg acc (train): {:.4f}\".format(avg_acc))\n",
        "        print(\"Avg loss (val): {:.4f}\".format(avg_loss_val))\n",
        "        print(\"Avg acc (val): {:.4f}\".format(avg_acc_val))\n",
        "        print('-' * 10)\n",
        "        print()\n",
        "        \n",
        "        if avg_acc_val > best_acc:\n",
        "            best_acc = avg_acc_val\n",
        "            best_model_wts = copy.deepcopy(vgg.state_dict())\n",
        "        \n",
        "    elapsed_time = time.time() - since\n",
        "    print()\n",
        "    print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
        "    print(\"Best acc: {:.4f}\".format(best_acc))\n",
        "    \n",
        "    vgg.load_state_dict(best_model_wts)\n",
        "    return vgg"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}