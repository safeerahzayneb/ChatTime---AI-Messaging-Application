{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YLL_Test_AlexNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yanli499/ChatTime/blob/Lucy_1/YLL_Test_AlexNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne2bpo2avzHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ALL import statements\n",
        "import os\n",
        "import shutil\n",
        "import copy\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.models\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCdCgvkgiqYw",
        "colab_type": "code",
        "outputId": "3a1cf418-6fb1-425e-f6da-40346e4cb870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Mount our Google Drive\n",
        "# re-run whenever needed\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir_dLCntisAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Global variables\n",
        "# classes are folders in each directory with these names\n",
        "classes = ['afraid','angry','disgusted','happy','neutral','sad','surprised']\n",
        "\n",
        "# emotion label for KDEF photos\n",
        "emotion_code = {\"AF\":\"afraid\", \"AN\":\"angry\", \"DI\":\"disgusted\", \"HA\":\"happy\", \n",
        "                \"NE\":\"neutral\", \"SA\":\"sad\", \"SU\":\"surprised\"}\n",
        "\n",
        "data_dir='/content/drive/My Drive/Colab Notebooks/Faces'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLljEYqZAWVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Call this function once only!\n",
        "\"\"\"\n",
        "Logic for sorting thru dataseta for desired images:\n",
        "KDEF:\n",
        "- Example file name: AF01ANS.JPG\n",
        "- Check:\n",
        "    - length of name = 7, for straight profile only, ends with \"S.jpg\"\n",
        "    - str[4:5] = {\"AF\":\"afraid\", \"AN\":\"angry\", \"DI\":\"disgusted\", \"HA\":\"happy\",\n",
        "    \"NE\":\"neutral\", \"SA\":sad\", \"SU\":\"surprised\"}\n",
        "\"\"\"\n",
        "\n",
        "def create_useful_dataset(): \n",
        "    # delete existing folder\n",
        "    if os.path.exists(data_dir+'/'):\n",
        "        shutil.rmtree(data_dir+'/')\n",
        "\n",
        "    # make new directories for each emotion class + train, val, test\n",
        "    try:\n",
        "        os.mkdir(data_dir)\n",
        "\n",
        "        for i in range(len(classes)):\n",
        "            os.mkdir(data_dir+'/'+classes[i])\n",
        "\n",
        "        os.mkdir(data_dir+'/train')\n",
        "        for i in range(len(classes)):\n",
        "            os.mkdir(data_dir+'/train/'+classes[i])\n",
        "        \n",
        "        os.mkdir(data_dir+'/val')\n",
        "        for i in range(len(classes)):\n",
        "            os.mkdir(data_dir+'/val/'+classes[i])\n",
        "\n",
        "        os.mkdir(data_dir+'/test')\n",
        "        for i in range(len(classes)):\n",
        "            os.mkdir(data_dir+'/test/'+classes[i])\n",
        "\n",
        "    except OSError:\n",
        "        print (\"Creation of the directories failed!\")\n",
        "    else:\n",
        "        print (\"Successfully created the directories!\")\n",
        "\n",
        "    # rootdir = path to KDEF main folder\n",
        "    rootdir = '/content/drive/My Drive/Colab Notebooks/PROJECT/KDEF/'\n",
        "\n",
        "    # go thru KDEF data + sort out desired photos\n",
        "    for subdir, dirs, files in os.walk(rootdir):\n",
        "        for file in files:\n",
        "            filename = subdir + os.sep + file\n",
        "            if (file.endswith(\"S.jpg\") or file.endswith(\"S.JPG\")): \n",
        "                \"\"\"\n",
        "                For each straight profile photo:\n",
        "                    - convert RGB --> Grayscale\n",
        "                    - make 4 copies of photo: original orientation, rotate 5 degrees\n",
        "                        clockwise (cw), rotate counter-clockwise (ccw), flip horizontally\n",
        "                    - resize all to 256 x 256 pixels, b/c will center crop to 224 x 224 later\n",
        "                    - then save in the corresponding emotion class folder\n",
        "                \"\"\"\n",
        "                img = Image.open(filename).convert('L')\n",
        "                img_cw = img.rotate(350)\n",
        "                img_ccw = img.rotate(10)\n",
        "                img_flip = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "                new_img = img.resize((256, 256))\n",
        "                new_img_cw = img_cw.resize((256, 256))\n",
        "                new_img_ccw = img_ccw.resize((256, 256))\n",
        "                new_img_flip = img_flip.resize((256, 256))\n",
        "\n",
        "                label = file[4:6]\n",
        "                new_img.save(data_dir+'/'+emotion_code[label]+'/'+file)\n",
        "                new_img_cw.save(data_dir+'/'+emotion_code[label]+'/'+'1'+file)\n",
        "                new_img_ccw.save(data_dir+'/'+emotion_code[label]+'/'+'2'+file)\n",
        "                new_img_flip.save(data_dir+'/'+emotion_code[label]+'/'+'3'+file)\n",
        "    \n",
        "    print (\"Finished creating useful dataset!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ONtGEPi4oIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_data_to_subsets():   \n",
        "    # Split data into train, val, test datasets (60:20:20)\n",
        "    # each class = ~568 images --> ~340 train, ~114 val, ~114 test\n",
        "\n",
        "    # divide data into train, val, + test\n",
        "    # for each emotion class, get filenames, shuffle, \n",
        "    # divide, move to corresponding folders\n",
        "    for cla in classes:\n",
        "        filepath = data_dir+'/'+cla\n",
        "        names = []\n",
        "\n",
        "        for file in os.listdir(filepath):\n",
        "            names.append(file)\n",
        "\n",
        "        random.shuffle(names)\n",
        "        num_files = len(names)\n",
        "\n",
        "        for ind, name in enumerate(names):\n",
        "            if(ind <= math.ceil(0.6 * num_files)):\n",
        "                # Move to train\n",
        "                shutil.move(filepath+'/'+name, data_dir+'/train/'+cla+'/'+name)\n",
        "            elif(ind <= math.ceil(0.8 * num_files)):\n",
        "                # Move to val\n",
        "                shutil.move(filepath+'/'+name, data_dir+'/val/'+cla+'/'+name)\n",
        "            else:\n",
        "                # Move to test\n",
        "                shutil.move(filepath+'/'+name, data_dir+'/test/'+cla+'/'+name)\n",
        "    \n",
        "    print (\"Finished splitting data to training, val, and test subsets\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2Fuh2e3nsyt",
        "colab_type": "code",
        "outputId": "fd056ca8-9a1d-4d67-b31d-ec2e51fd608e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Run only when necessary\n",
        "create_useful_dataset()\n",
        "split_data_to_subsets()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully created the directories!\n",
            "Finished creating useful dataset!\n",
            "Finished splitting data to training, val, and test subsets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OV-9PAKI1-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alexnet = torchvision.models.alexnet(pretrained=True)\n",
        "torch.manual_seed(1) # set the random seed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxrf7MuEI4Kn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# crop all images to 224 x 224 for all datasets\n",
        "# generate image folders + data loaders for train, val, test\n",
        "\n",
        "# Global Variables\n",
        "batch_size = 1\n",
        "data_transform = transforms.Compose([transforms.CenterCrop(224), transforms.ToTensor()])\n",
        "\n",
        "dir_paths = {\n",
        "    'train': os.path.join(data_dir, 'train/'),\n",
        "    'val': os.path.join(data_dir, 'val/'),\n",
        "    'test': os.path.join(data_dir, 'test/')\n",
        "}\n",
        "\n",
        "image_datasets = {\n",
        "    'train': datasets.ImageFolder(\n",
        "        dir_paths['train'], \n",
        "        transform=data_transform\n",
        "    ),\n",
        "    'val': datasets.ImageFolder(\n",
        "        dir_paths['val'], \n",
        "        transform=data_transform\n",
        "    ),\n",
        "    'test': datasets.ImageFolder(\n",
        "        dir_paths['test'], \n",
        "        transform=data_transform\n",
        "    )\n",
        "}\n",
        "\n",
        "data_loaders = {\n",
        "    'train': torch.utils.data.DataLoader(\n",
        "        image_datasets['train'], batch_size=batch_size\n",
        "    ),\n",
        "    'val': torch.utils.data.DataLoader(\n",
        "        image_datasets['val'], batch_size=batch_size\n",
        "    ),\n",
        "    'test': torch.utils.data.DataLoader(\n",
        "        image_datasets['test'], batch_size=batch_size\n",
        "    )\n",
        "}\n",
        "\n",
        "# get size of each dataset\n",
        "dataset_sizes = {\n",
        "    'train': len(image_datasets['train']),\n",
        "    'val': len(image_datasets['val']),\n",
        "    'test': len(image_datasets['test']) \n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhMNWF1POQR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving features as tensors in folder structure\n",
        "def create_tensor_folders():\n",
        "    # delete existing folder\n",
        "    if os.path.exists(data_dir+'alexnet'):\n",
        "        shutil.rmtree(data_dir+'alexnet')\n",
        "\n",
        "    try:\n",
        "        # create train, val, test folders for VGG features\n",
        "        os.mkdir(data_dir+'alexnet')\n",
        "        os.mkdir(data_dir+'alexnet/train')\n",
        "        os.mkdir(data_dir+'alexnet/val')\n",
        "        os.mkdir(data_dir+'alexnet/test')\n",
        "\n",
        "        for i in range(len(classes)):\n",
        "            os.mkdir(data_dir+'alexnet/train/'+classes[i])\n",
        "            os.mkdir(data_dir+'alexnet/val/'+classes[i])\n",
        "            os.mkdir(data_dir+'alexnet/test/'+classes[i])\n",
        "\n",
        "    except OSError:\n",
        "        print (\"Creation of the directories failed!\")\n",
        "    else:\n",
        "        print (\"Successfully created the directories!\")\n",
        "\n",
        "def save_tensor_helper(dir_name, features, label, img_num):\n",
        "    # save tensor to appropriate emotion folder\n",
        "    path='/content/drive/My Drive/Colab Notebooks/Faces/'+dir_name\n",
        "\n",
        "    if (label.item() == 0):\n",
        "        torch.save(features, path + '/afraid/features_' + str(img_num) + '.tensor')\n",
        "    if (label.item() == 1):\n",
        "        torch.save(features, path + '/angry/features_' + str(img_num) + '.tensor')\n",
        "    if (label.item() == 2):\n",
        "        torch.save(features, path + '/disgusted/features_' + str(img_num) + '.tensor')\n",
        "    if (label.item() == 3):\n",
        "        torch.save(features, path + '/happy/features_' + str(img_num) + '.tensor')\n",
        "    if (label.item() == 4):\n",
        "        torch.save(features, path + '/neutral/features_' + str(img_num) + '.tensor')\n",
        "    if (label.item() == 5):\n",
        "        torch.save(features, path + '/sad/features_' + str(img_num) + '.tensor')\n",
        "    if (label.item() == 6):\n",
        "        torch.save(features, path + '/surprised/features_' + str(img_num) + '.tensor')\n",
        "\n",
        "def save_tensors():\n",
        "    # save tensors to train, val, test folders\n",
        "    i = 0\n",
        "    for img, label in data_loaders['train']:\n",
        "        features = alexnet.features(img)\n",
        "        save_tensor_helper('alexnet/train', features, label, i)\n",
        "        i+=1\n",
        "\n",
        "    i = 0\n",
        "    for img, label in data_loaders['val']:\n",
        "        features = alexnet.features(img)\n",
        "        save_tensor_helper('alexnet/val', features, label, i)\n",
        "        i+=1\n",
        "\n",
        "    i = 0\n",
        "    for img, label in data_loaders['test']:\n",
        "        features = vgg16.features(img)\n",
        "        save_tensor_helper('vgg16/test', features, label, i)\n",
        "        i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUV-sryldk-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "create_tensor_folders()\n",
        "save_tensors()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jRGd1Pml3rp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Artifical Neural Network Architecture\n",
        "class ANNClassifier_Alexnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ANNClassifier_Alexnet, self).__init__()\n",
        "        self.name = \"alexnet_ann\"\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 300)\n",
        "        self.fc2 = nn.Linear(300, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 256 * 6 * 6) #flatten feature data\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgA7U1k0mFfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_feature(loc): \n",
        "    return torch.load(loc)\n",
        "\n",
        "# Data Loading\n",
        "def get_features_data_loader(data_dir, batch_size):\n",
        "    # define training and test data directories\n",
        "    train_dir = os.path.join(data_dir, 'train/')\n",
        "    val_dir = os.path.join(data_dir, 'val/')\n",
        "    test_dir = os.path.join(data_dir, 'test/')\n",
        "\n",
        "    train_data = datasets.DatasetFolder(train_dir, loader = load_feature, extensions = '.tensor')\n",
        "    val_data = datasets.DatasetFolder(val_dir, loader = load_feature, extensions = '.tensor')\n",
        "    test_data = datasets.DatasetFolder(test_dir, loader = load_feature, extensions = '.tensor')\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
        "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
        "    \n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "# Training code\n",
        "def get_model_name(name, batch_size, learning_rate, epoch):\n",
        "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
        "    Args:\n",
        "        config: Configuration object containing the hyperparameters\n",
        "    Returns:\n",
        "        path: A string with the hyperparameter name and value concatenated\n",
        "    \"\"\"\n",
        "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
        "                batch_size, learning_rate, epoch)\n",
        "    return path\n",
        "  \n",
        "def get_accuracy(model, loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for imgs, labels in loader:\n",
        "        imgs = torch.from_numpy(imgs.detach().numpy())\n",
        "        output = model(imgs)\n",
        "        prob = F.softmax(output)\n",
        "        \n",
        "        #select index with maximum prediction score\n",
        "        pred = prob.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "        \n",
        "    return correct / total\n",
        "\n",
        "def evaluate(net, loader, criterion):\n",
        "    \"\"\" Evaluate the network on the validation set.\n",
        "     Args:\n",
        "         net: PyTorch neural network object\n",
        "         loader: PyTorch data loader for the validation set\n",
        "         criterion: The loss function\n",
        "     Returns:\n",
        "         acc: A scalar for the avg classification acc over the validation set\n",
        "         loss: A scalar for the average loss function over the validation set\n",
        "     \"\"\"\n",
        "    total_loss = 0.0\n",
        "    total_epoch = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, data in enumerate(loader, 0):\n",
        "        imgs, labels = data\n",
        "\n",
        "        imgs = torch.from_numpy(imgs.detach().numpy())              \n",
        "        out = model(imgs)             # forward pass\n",
        "        prob = F.softmax(out)\n",
        "        loss = criterion(prob, labels)\n",
        "        \n",
        "        #select index with maximum prediction score\n",
        "        pred = prob.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "        \n",
        "        total_loss += loss\n",
        "        total_epoch += len(labels)\n",
        "    \n",
        "    acc = correct / total\n",
        "    loss = float(total_loss) / (i + 1)\n",
        "    \n",
        "    return acc, loss\n",
        "\n",
        "# Training Curve\n",
        "def plot_training_curve(path):\n",
        "    \"\"\" Plots the training curve for a model run, given the csv files\n",
        "    containing the train/validation accuracy/loss.\n",
        "    Args:\n",
        "        path: The base path of the csv files produced during training\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    train_acc = np.loadtxt(\"{}_train_acc.csv\".format(path))\n",
        "    val_acc = np.loadtxt(\"{}_val_acc.csv\".format(path))\n",
        "    train_loss = np.loadtxt(\"{}_train_loss.csv\".format(path))\n",
        "    val_loss = np.loadtxt(\"{}_val_loss.csv\".format(path))\n",
        "    \n",
        "    n = len(train_acc) # number of epochs\n",
        "    \n",
        "    plt.title(\"Train vs Validation Loss\")\n",
        "    plt.plot(range(1,n+1), train_loss, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_loss, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "    \n",
        "    plt.title(\"Train vs Validation Accuracy\")\n",
        "    plt.plot(range(1,n+1), train_acc, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
        "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
        "\n",
        "    \n",
        "def train_net(net, batch_size=64, learning_rate=0.01, num_epochs=30,\n",
        "    data_dir='/content/drive/My Drive/Colab Notebooks/Faces/'):\n",
        "\n",
        "    # Fixed PyTorch random seed for reproducible result\n",
        "    torch.manual_seed(1000)\n",
        "    \n",
        "    # Obtain the PyTorch data loader objects to load batches of the datasets\n",
        "    train_loader, val_loader, test_loader = get_features_data_loader(data_dir, batch_size)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "    \n",
        "    # Set up some numpy arrays to store the training/test loss/erruracy\n",
        "    train_acc = np.zeros(num_epochs)\n",
        "    train_loss = np.zeros(num_epochs)\n",
        "    val_acc = np.zeros(num_epochs)\n",
        "    val_loss = np.zeros(num_epochs)\n",
        "    \n",
        "    # Train the network\n",
        "    # Loop over the data iterator and sample a new batch of training data\n",
        "    # Get the output from the network, and optimize our loss function.\n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "        total_train_loss = 0.0\n",
        "        total_train_acc = 0.0\n",
        "        total_epoch = 0\n",
        "\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            # Get the inputs\n",
        "            imgs, labels = data\n",
        "            \n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass, backward pass, and optimize\n",
        "            imgs = torch.from_numpy(imgs.detach().numpy())\n",
        "              \n",
        "            out = model(imgs) # forward pass\n",
        "            prob = F.softmax(out)\n",
        "            loss = criterion(prob, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            total_train_loss += loss\n",
        "            total_epoch += len(labels)\n",
        "\n",
        "        train_acc[epoch] = get_accuracy(net, train_loader)\n",
        "        train_loss[epoch] = float(total_train_loss) / (i+1)\n",
        "        val_acc[epoch], val_loss[epoch] = evaluate(net, val_loader, criterion)\n",
        "        \n",
        "        print((\"Epoch {}: Train acc: {}, Train loss: {} |\"+\n",
        "               \"Validation acc: {}, Validation loss: {}\").format(\n",
        "                   epoch + 1,\n",
        "                   train_acc[epoch],\n",
        "                   train_loss[epoch],\n",
        "                   val_acc[epoch],\n",
        "                   val_loss[epoch]))\n",
        "        \n",
        "        # Save the current model (checkpoint) to a file\n",
        "        model_path = get_model_name(net.name, batch_size, learning_rate, epoch)\n",
        "        torch.save(net.state_dict(), model_path)\n",
        "    \n",
        "    print('Finished Training')\n",
        "    \n",
        "    # Write the train/test loss/accuracy into CSV file for plotting later\n",
        "    epochs = np.arange(1, num_epochs + 1)\n",
        "    np.savetxt(\"{}_train_acc.csv\".format(model_path), train_acc)\n",
        "    np.savetxt(\"{}_train_loss.csv\".format(model_path), train_loss)\n",
        "    np.savetxt(\"{}_val_acc.csv\".format(model_path), val_acc)\n",
        "    np.savetxt(\"{}_val_loss.csv\".format(model_path), val_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMHzZEp44MH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ANNClassifier_Alexnet()\n",
        "train_net(model, batch_size=128, learning_rate=0.001, num_epochs=150, #CHANGE TO THE OPTIMAL ONE!\n",
        "    data_dir='/content/drive/My Drive/Colab Notebooks/Faces/alexnet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBO79gZH4StT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = get_model_name(\"alexnet_ann\", batch_size=128, learning_rate=0.001, epoch=149)\n",
        "plot_training_curve('/content/' + model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZANRBIiYd2F_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ANNClassifier_Alexnet()\n",
        "model_path = get_model_name(\"alexnet_ann\", batch_size=128, learning_rate=0.001, epoch=149)\n",
        "\n",
        "state = torch.load('/content/' + model_path)\n",
        "model.load_state_dict(state)\n",
        "\n",
        "data_dir='/content/drive/My Drive/Colab Notebooks/Faces/alexnet'\n",
        "\n",
        "train_loader, val_loader, test_loader = get_features_data_loader(data_dir=data_dir, batch_size=128)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "test_acc, test_loss = evaluate(model, test_loader, criterion)\n",
        "print(\"Test classification accuracy:\", test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}