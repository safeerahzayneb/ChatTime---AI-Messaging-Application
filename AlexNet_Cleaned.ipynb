{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YLL_Test_AlexNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yanli499/ChatTime/blob/master/AlexNet_Cleaned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne2bpo2avzHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ALL import statements\n",
        "import os\n",
        "import shutil\n",
        "import copy\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.models\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCdCgvkgiqYw",
        "colab_type": "code",
        "outputId": "baca5170-ced3-45d5-cb02-061a8509cd50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Mount our Google Drive\n",
        "# re-run whenever needed\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir_dLCntisAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Global variables\n",
        "# classes are folders in each directory with these names\n",
        "classes = ['afraid','angry','disgusted','happy','neutral','sad','surprised']\n",
        "\n",
        "# emotion label for KDEF photos\n",
        "emotion_code = {\"AF\":\"afraid\", \"AN\":\"angry\", \"DI\":\"disgusted\", \"HA\":\"happy\", \n",
        "                \"NE\":\"neutral\", \"SA\":\"sad\", \"SU\":\"surprised\"}\n",
        "\n",
        "data_dir='/content/drive/My Drive/Colab Notebooks/Faces'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLljEYqZAWVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Call this function once only!\n",
        "\"\"\"\n",
        "Logic for sorting thru dataseta for desired images:\n",
        "KDEF:\n",
        "- Example file name: AF01ANS.JPG\n",
        "- Check:\n",
        "    - length of name = 7, for straight profile only, ends with \"S.jpg\"\n",
        "    - str[4:5] = {\"AF\":\"afraid\", \"AN\":\"angry\", \"DI\":\"disgusted\", \"HA\":\"happy\",\n",
        "    \"NE\":\"neutral\", \"SA\":sad\", \"SU\":\"surprised\"}\n",
        "\"\"\"\n",
        "\n",
        "def create_useful_dataset(): \n",
        "    # delete existing folder\n",
        "    if os.path.exists(data_dir+'/'):\n",
        "        shutil.rmtree(data_dir+'/')\n",
        "\n",
        "    # make new directories for each emotion class + train, val, test\n",
        "    try:\n",
        "        os.mkdir(data_dir)\n",
        "        os.mkdir(data_dir+'/train')\n",
        "        os.mkdir(data_dir+'/val')\n",
        "        os.mkdir(data_dir+'/test')\n",
        "\n",
        "        for i in classes:\n",
        "            os.mkdir(data_dir+'/'+i)\n",
        "            os.mkdir(data_dir+'/train/'+i)\n",
        "            os.mkdir(data_dir+'/val/'+i)\n",
        "            os.mkdir(data_dir+'/test/'+i)\n",
        "\n",
        "    except OSError:\n",
        "        print (\"Creation of the directories failed!\")\n",
        "    else:\n",
        "        print (\"Successfully created the directories!\")\n",
        "\n",
        "    # rootdir = path to KDEF main folder\n",
        "    rootdir = '/content/drive/My Drive/Colab Notebooks/PROJECT/KDEF/'\n",
        "\n",
        "    # go thru KDEF data + sort out desired photos\n",
        "    for subdir, dirs, files in os.walk(rootdir):\n",
        "        for file in files:\n",
        "            filename = subdir + os.sep + file\n",
        "            if (file.endswith(\"S.jpg\") or file.endswith(\"S.JPG\")): \n",
        "                \"\"\"\n",
        "                For each straight profile photo:\n",
        "                    - convert RGB --> Grayscale\n",
        "                    - make 4 copies of photo: original orientation, rotate 5 degrees\n",
        "                        clockwise (cw), rotate counter-clockwise (ccw), flip horizontally\n",
        "                    - resize all to 256 x 256 pixels, b/c will center crop to 224 x 224 later\n",
        "                    - then save in the corresponding emotion class folder\n",
        "                \"\"\"\n",
        "                img = Image.open(filename).convert('L')\n",
        "                img_cw = img.rotate(350)\n",
        "                img_ccw = img.rotate(10)\n",
        "                img_flip = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "                new_img = img.resize((256, 256))\n",
        "                new_img_cw = img_cw.resize((256, 256))\n",
        "                new_img_ccw = img_ccw.resize((256, 256))\n",
        "                new_img_flip = img_flip.resize((256, 256))\n",
        "\n",
        "                label = file[4:6]\n",
        "                new_img.save(data_dir+'/'+emotion_code[label]+'/'+file)\n",
        "                new_img_cw.save(data_dir+'/'+emotion_code[label]+'/'+'1'+file)\n",
        "                new_img_ccw.save(data_dir+'/'+emotion_code[label]+'/'+'2'+file)\n",
        "                new_img_flip.save(data_dir+'/'+emotion_code[label]+'/'+'3'+file)\n",
        "    \n",
        "    print (\"Finished creating useful dataset!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ONtGEPi4oIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_data_to_subsets():   \n",
        "    \"\"\"\n",
        "    Split data into train, val, test datasets (60:20:20)\n",
        "    each class = ~568 images --> ~340 train, ~114 val, ~114 test\n",
        "    \"\"\"\n",
        "    # divide data into train, val, + test\n",
        "    # for each emotion class, get filenames, shuffle, \n",
        "    # divide, move to corresponding folders\n",
        "    for cla in classes:\n",
        "        filepath = data_dir+'/'+cla\n",
        "        names = []\n",
        "\n",
        "        for file in os.listdir(filepath):\n",
        "            names.append(file)\n",
        "\n",
        "        random.shuffle(names)\n",
        "        num_files = len(names)\n",
        "\n",
        "        for ind, name in enumerate(names):\n",
        "            if(ind <= math.ceil(0.6 * num_files)):\n",
        "                # Move to train\n",
        "                shutil.move(filepath+'/'+name, data_dir+'/train/'+cla+'/'+name)\n",
        "            elif(ind <= math.ceil(0.8 * num_files)):\n",
        "                # Move to val\n",
        "                shutil.move(filepath+'/'+name, data_dir+'/val/'+cla+'/'+name)\n",
        "            else:\n",
        "                # Move to test\n",
        "                shutil.move(filepath+'/'+name, data_dir+'/test/'+cla+'/'+name)\n",
        "    \n",
        "    print (\"Finished splitting data to training, val, and test subsets\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2Fuh2e3nsyt",
        "colab_type": "code",
        "outputId": "c2abd8a5-e06e-417f-b6f2-a4a4b35a5492",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Run only when necessary\n",
        "create_useful_dataset()\n",
        "split_data_to_subsets()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully created the directories!\n",
            "Finished creating useful dataset!\n",
            "Finished splitting data to training, val, and test subsets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OV-9PAKI1-B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad64e331-7f86-4d66-be2e-226b4d1e79a3"
      },
      "source": [
        "alexnet = torchvision.models.alexnet(pretrained=True)\n",
        "torch.manual_seed(1) # set the random seed"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f3e2d48f910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxrf7MuEI4Kn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# crop all images to 224 x 224 for all datasets\n",
        "# generate image folders + data loaders for train, val, test\n",
        "\n",
        "# Global Variables\n",
        "batch_size = 1\n",
        "data_transform = transforms.Compose([transforms.CenterCrop(224), transforms.ToTensor()])\n",
        "\n",
        "dir_paths = {\n",
        "    'train': os.path.join(data_dir, 'train/'),\n",
        "    'val': os.path.join(data_dir, 'val/'),\n",
        "    'test': os.path.join(data_dir, 'test/')\n",
        "}\n",
        "\n",
        "image_datasets = {\n",
        "    'train': datasets.ImageFolder(\n",
        "        dir_paths['train'], \n",
        "        transform=data_transform\n",
        "    ),\n",
        "    'val': datasets.ImageFolder(\n",
        "        dir_paths['val'], \n",
        "        transform=data_transform\n",
        "    ),\n",
        "    'test': datasets.ImageFolder(\n",
        "        dir_paths['test'], \n",
        "        transform=data_transform\n",
        "    )\n",
        "}\n",
        "\n",
        "data_loaders = {\n",
        "    'train': torch.utils.data.DataLoader(\n",
        "        image_datasets['train'], batch_size=batch_size\n",
        "    ),\n",
        "    'val': torch.utils.data.DataLoader(\n",
        "        image_datasets['val'], batch_size=batch_size\n",
        "    ),\n",
        "    'test': torch.utils.data.DataLoader(\n",
        "        image_datasets['test'], batch_size=batch_size\n",
        "    )\n",
        "}\n",
        "\n",
        "# get size of each dataset\n",
        "dataset_sizes = {\n",
        "    'train': len(image_datasets['train']),\n",
        "    'val': len(image_datasets['val']),\n",
        "    'test': len(image_datasets['test']) \n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhMNWF1POQR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving features as tensors in folder structure\n",
        "def create_tensor_folders():\n",
        "    # delete existing folder\n",
        "    if os.path.exists(data_dir+'/alexnet'):\n",
        "        shutil.rmtree(data_dir+'/alexnet')\n",
        "\n",
        "    try:\n",
        "        # create train, val, test folders for VGG features\n",
        "        os.mkdir(data_dir+'/alexnet')\n",
        "        os.mkdir(data_dir+'/alexnet/train')\n",
        "        os.mkdir(data_dir+'/alexnet/val')\n",
        "        os.mkdir(data_dir+'/alexnet/test')\n",
        "\n",
        "        for i in range(len(classes)):\n",
        "            os.mkdir(data_dir+'/alexnet/train/'+classes[i])\n",
        "            os.mkdir(data_dir+'/alexnet/val/'+classes[i])\n",
        "            os.mkdir(data_dir+'/alexnet/test/'+classes[i])\n",
        "\n",
        "    except OSError:\n",
        "        print (\"Creation of the directories failed!\")\n",
        "    else:\n",
        "        print (\"Successfully created the directories!\")\n",
        "\n",
        "def save_tensor_helper(dir_name, features, label, img_num):\n",
        "    # save tensor to appropriate emotion folder\n",
        "    path='/content/drive/My Drive/Colab Notebooks/Faces/'+dir_name\n",
        "\n",
        "    if (label.item() == 0):\n",
        "        torch.save(features, path + '/afraid/features_' + str(img_num) + '.tensor')\n",
        "    if (label.item() == 1):\n",
        "        torch.save(features, path + '/angry/features_' + str(img_num) + '.tensor')\n",
        "    if (label.item() == 2):\n",
        "        torch.save(features, path + '/disgusted/features_' + str(img_num) + '.tensor')\n",
        "    if (label.item() == 3):\n",
        "        torch.save(features, path + '/happy/features_' + str(img_num) + '.tensor')\n",
        "    if (label.item() == 4):\n",
        "        torch.save(features, path + '/neutral/features_' + str(img_num) + '.tensor')\n",
        "    if (label.item() == 5):\n",
        "        torch.save(features, path + '/sad/features_' + str(img_num) + '.tensor')\n",
        "    if (label.item() == 6):\n",
        "        torch.save(features, path + '/surprised/features_' + str(img_num) + '.tensor')\n",
        "\n",
        "def save_tensors():\n",
        "    # save tensors to train, val, test folders\n",
        "    i = 0\n",
        "    for img, label in data_loaders['train']:\n",
        "        features = alexnet.features(img)\n",
        "        save_tensor_helper('alexnet/train', features, label, i)\n",
        "        i+=1\n",
        "\n",
        "    i = 0\n",
        "    for img, label in data_loaders['val']:\n",
        "        features = alexnet.features(img)\n",
        "        save_tensor_helper('alexnet/val', features, label, i)\n",
        "        i+=1\n",
        "\n",
        "    i = 0\n",
        "    for img, label in data_loaders['test']:\n",
        "        features = alexnet.features(img)\n",
        "        save_tensor_helper('alexnet/test', features, label, i)\n",
        "        i+=1\n",
        "    \n",
        "    print(\"Tensors saved!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUV-sryldk-t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "64158258-1460-4f8e-cfeb-f6283cdb6e26"
      },
      "source": [
        "create_tensor_folders()\n",
        "save_tensors()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully created the directories!\n",
            "Tensors saved!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jRGd1Pml3rp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Artifical Neural Network Architecture\n",
        "class ANNClassifier_Alexnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ANNClassifier_Alexnet, self).__init__()\n",
        "        self.name = \"alexnet_ann\"\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 300)\n",
        "        self.fc2 = nn.Linear(300, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 256 * 6 * 6) #flatten feature data\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgA7U1k0mFfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_feature(loc): \n",
        "    return torch.load(loc)\n",
        "\n",
        "def get_features_data_loader(data_dir, batch_size): # Data Loading\n",
        "    # define training and test data directories\n",
        "    train_dir = os.path.join(data_dir, 'train/')\n",
        "    val_dir = os.path.join(data_dir, 'val/')\n",
        "    test_dir = os.path.join(data_dir, 'test/')\n",
        "\n",
        "    train_data = datasets.DatasetFolder(train_dir, loader=load_feature, extensions = '.tensor')\n",
        "    val_data = datasets.DatasetFolder(val_dir, loader=load_feature, extensions = '.tensor')\n",
        "    test_data = datasets.DatasetFolder(test_dir, loader=load_feature, extensions = '.tensor')\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
        "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
        "    \n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "def get_model_name(name, batch_size, learning_rate, epoch):\n",
        "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
        "    Args:\n",
        "        config: Configuration object containing the hyperparameters\n",
        "    Returns:\n",
        "        path: A string with the hyperparameter name and value concatenated\n",
        "    \"\"\"\n",
        "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
        "                batch_size, learning_rate, epoch)\n",
        "    return path\n",
        "  \n",
        "def get_accuracy(model, loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for imgs, labels in loader:\n",
        "        imgs = torch.from_numpy(imgs.detach().numpy())\n",
        "        output = model(imgs)\n",
        "        prob = F.softmax(output)\n",
        "        \n",
        "        #select index with maximum prediction score\n",
        "        pred = prob.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "        \n",
        "    return correct / total\n",
        "\n",
        "def evaluate(net, loader, criterion):\n",
        "    \"\"\" Evaluate the network on the validation set.\n",
        "     Args:\n",
        "         net: PyTorch neural network object\n",
        "         loader: PyTorch data loader for the validation set\n",
        "         criterion: The loss function\n",
        "     Returns:\n",
        "         acc: A scalar for the avg classification acc over the validation set\n",
        "         loss: A scalar for the average loss function over the validation set\n",
        "     \"\"\"\n",
        "    total_loss = 0.0\n",
        "    total_epoch = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, data in enumerate(loader, 0):\n",
        "        imgs, labels = data\n",
        "\n",
        "        imgs = torch.from_numpy(imgs.detach().numpy())              \n",
        "        out = model(imgs) # forward pass\n",
        "        prob = F.softmax(out)\n",
        "        loss = criterion(prob, labels)\n",
        "        \n",
        "        #select index with maximum prediction score\n",
        "        pred = prob.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "        \n",
        "        total_loss += loss\n",
        "        total_epoch += len(labels)\n",
        "    \n",
        "    acc = correct / total\n",
        "    loss = float(total_loss) / (i + 1)\n",
        "    \n",
        "    return acc, loss\n",
        "\n",
        "def plot_training_curve(path):\n",
        "    \"\"\" Plots the training curve for a model run, given the csv files\n",
        "    containing the train/validation accuracy/loss.\n",
        "    Args:\n",
        "        path: The base path of the csv files produced during training\n",
        "    \"\"\"\n",
        "    train_acc = np.loadtxt(\"{}_train_acc.csv\".format(path))\n",
        "    val_acc = np.loadtxt(\"{}_val_acc.csv\".format(path))\n",
        "    train_loss = np.loadtxt(\"{}_train_loss.csv\".format(path))\n",
        "    val_loss = np.loadtxt(\"{}_val_loss.csv\".format(path))\n",
        "    \n",
        "    n = len(train_acc) # number of epochs\n",
        "    \n",
        "    plt.title(\"Train vs Validation Loss\")\n",
        "    plt.plot(range(1,n+1), train_loss, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_loss, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "    \n",
        "    plt.title(\"Train vs Validation Accuracy\")\n",
        "    plt.plot(range(1,n+1), train_acc, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
        "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
        "\n",
        "    \n",
        "def train_net(net, batch_size=64, learning_rate=0.01, num_epochs=30,\n",
        "    data_dir='/content/drive/My Drive/Colab Notebooks/Faces/'):\n",
        "\n",
        "    # Fixed PyTorch random seed for reproducible result\n",
        "    torch.manual_seed(1000)\n",
        "    \n",
        "    # Obtain the PyTorch data loader objects to load batches of the datasets\n",
        "    train_loader, val_loader, test_loader = get_features_data_loader(data_dir, batch_size)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "    \n",
        "    # Set up some numpy arrays to store the training/test loss/erruracy\n",
        "    train_acc = np.zeros(num_epochs)\n",
        "    train_loss = np.zeros(num_epochs)\n",
        "    val_acc = np.zeros(num_epochs)\n",
        "    val_loss = np.zeros(num_epochs)\n",
        "    \n",
        "    # Train the network\n",
        "    # Loop over the data iterator and sample a new batch of training data\n",
        "    # Get the output from the network, and optimize our loss function.\n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "        total_train_loss = 0.0\n",
        "        total_train_acc = 0.0\n",
        "        total_epoch = 0\n",
        "\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            # Get the inputs\n",
        "            imgs, labels = data\n",
        "            \n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass, backward pass, and optimize\n",
        "            imgs = torch.from_numpy(imgs.detach().numpy())\n",
        "              \n",
        "            out = model(imgs) # forward pass\n",
        "            prob = F.softmax(out)\n",
        "            loss = criterion(prob, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            total_train_loss += loss\n",
        "            total_epoch += len(labels)\n",
        "\n",
        "        train_acc[epoch] = get_accuracy(net, train_loader)\n",
        "        train_loss[epoch] = float(total_train_loss) / (i+1)\n",
        "        val_acc[epoch], val_loss[epoch] = evaluate(net, val_loader, criterion)\n",
        "        \n",
        "        print((\"Epoch {}: Train acc: {}, Train loss: {} |\"+\n",
        "               \"Validation acc: {}, Validation loss: {}\").format(\n",
        "                   epoch + 1,\n",
        "                   train_acc[epoch],\n",
        "                   train_loss[epoch],\n",
        "                   val_acc[epoch],\n",
        "                   val_loss[epoch]))\n",
        "        \n",
        "        # Save the current model (checkpoint) to a file\n",
        "        model_path = get_model_name(net.name, batch_size, learning_rate, epoch)\n",
        "        torch.save(net.state_dict(), model_path)\n",
        "    \n",
        "    print('Finished Training')\n",
        "    \n",
        "    # Write the train/test loss/accuracy into CSV file for plotting later\n",
        "    epochs = np.arange(1, num_epochs + 1)\n",
        "    np.savetxt(\"{}_train_acc.csv\".format(model_path), train_acc)\n",
        "    np.savetxt(\"{}_train_loss.csv\".format(model_path), train_loss)\n",
        "    np.savetxt(\"{}_val_acc.csv\".format(model_path), val_acc)\n",
        "    np.savetxt(\"{}_val_loss.csv\".format(model_path), val_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMHzZEp44MH5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb109c80-6e56-4b84-d7b5-e2f67c308e1f"
      },
      "source": [
        "model = ANNClassifier_Alexnet()\n",
        "train_net(model, batch_size=128, learning_rate=0.001, num_epochs=150,\n",
        "    data_dir='/content/drive/My Drive/Colab Notebooks/Faces/alexnet')"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:152: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:67: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: Train acc: 0.19298245614035087, Train loss: 1.991371556332237 |Validation acc: 0.19423558897243107, Validation loss: 1.9511304582868303\n",
            "Epoch 2: Train acc: 0.29406850459482037, Train loss: 1.9643450285259045 |Validation acc: 0.2832080200501253, Validation loss: 1.9447205407278878\n",
            "Epoch 3: Train acc: 0.27485380116959063, Train loss: 1.9552616320158307 |Validation acc: 0.2744360902255639, Validation loss: 1.9378997257777624\n",
            "Epoch 4: Train acc: 0.24143692564745195, Train loss: 1.948659194143195 |Validation acc: 0.24060150375939848, Validation loss: 1.9315038408551897\n",
            "Epoch 5: Train acc: 0.23976608187134502, Train loss: 1.9446124026649876 |Validation acc: 0.23684210526315788, Validation loss: 1.9250707626342773\n",
            "Epoch 6: Train acc: 0.24101921470342522, Train loss: 1.9400062561035156 |Validation acc: 0.23934837092731828, Validation loss: 1.9181295122419084\n",
            "Epoch 7: Train acc: 0.25647451963241436, Train loss: 1.9359785381116366 |Validation acc: 0.24436090225563908, Validation loss: 1.9109864916120256\n",
            "Epoch 8: Train acc: 0.26399331662489556, Train loss: 1.932002017372533 |Validation acc: 0.2506265664160401, Validation loss: 1.9023914337158203\n",
            "Epoch 9: Train acc: 0.2819548872180451, Train loss: 1.9270641929224919 |Validation acc: 0.2756892230576441, Validation loss: 1.8936117717197962\n",
            "Epoch 10: Train acc: 0.297827903091061, Train loss: 1.9212377447831004 |Validation acc: 0.2869674185463659, Validation loss: 1.8833293914794922\n",
            "Epoch 11: Train acc: 0.316624895572264, Train loss: 1.9153189408151727 |Validation acc: 0.3057644110275689, Validation loss: 1.873528344290597\n",
            "Epoch 12: Train acc: 0.33458646616541354, Train loss: 1.907371721769634 |Validation acc: 0.3208020050125313, Validation loss: 1.8620779854910714\n",
            "Epoch 13: Train acc: 0.3579782790309106, Train loss: 1.8997690301192434 |Validation acc: 0.34210526315789475, Validation loss: 1.8509432928902763\n",
            "Epoch 14: Train acc: 0.3868003341687552, Train loss: 1.8884492171438116 |Validation acc: 0.37218045112781956, Validation loss: 1.8348249707903181\n",
            "Epoch 15: Train acc: 0.3968253968253968, Train loss: 1.8826115256861637 |Validation acc: 0.38471177944862156, Validation loss: 1.8245438167027064\n",
            "Epoch 16: Train acc: 0.41604010025062654, Train loss: 1.8663719578793174 |Validation acc: 0.40225563909774437, Validation loss: 1.8029956817626953\n",
            "Epoch 17: Train acc: 0.4344193817878028, Train loss: 1.8620352494089227 |Validation acc: 0.41353383458646614, Validation loss: 1.7944935389927454\n",
            "Epoch 18: Train acc: 0.4340016708437761, Train loss: 1.8414812589946545 |Validation acc: 0.40100250626566414, Validation loss: 1.767505373273577\n",
            "Epoch 19: Train acc: 0.4548872180451128, Train loss: 1.8382821334035773 |Validation acc: 0.41353383458646614, Validation loss: 1.758742196219308\n",
            "Epoch 20: Train acc: 0.4519632414369256, Train loss: 1.8178379661158512 |Validation acc: 0.41729323308270677, Validation loss: 1.7339469364711217\n",
            "Epoch 21: Train acc: 0.46825396825396826, Train loss: 1.810530612343236 |Validation acc: 0.4348370927318296, Validation loss: 1.7200994491577148\n",
            "Epoch 22: Train acc: 0.4778613199665831, Train loss: 1.7969715720728825 |Validation acc: 0.43358395989974935, Validation loss: 1.7048486982073103\n",
            "Epoch 23: Train acc: 0.49331662489557226, Train loss: 1.7843123988101357 |Validation acc: 0.4598997493734336, Validation loss: 1.68876770564488\n",
            "Epoch 24: Train acc: 0.49916457811194653, Train loss: 1.7738783986944902 |Validation acc: 0.45864661654135336, Validation loss: 1.6771039962768555\n",
            "Epoch 25: Train acc: 0.5221386800334169, Train loss: 1.7620739183927838 |Validation acc: 0.48621553884711777, Validation loss: 1.6645682198660714\n",
            "Epoch 26: Train acc: 0.5263157894736842, Train loss: 1.7516381113152755 |Validation acc: 0.5, Validation loss: 1.6541143144880022\n",
            "Epoch 27: Train acc: 0.5421888053467001, Train loss: 1.7409019470214844 |Validation acc: 0.5225563909774437, Validation loss: 1.643685749598912\n",
            "Epoch 28: Train acc: 0.551796157059315, Train loss: 1.7311925386127673 |Validation acc: 0.5300751879699248, Validation loss: 1.6346964154924666\n",
            "Epoch 29: Train acc: 0.5680868838763575, Train loss: 1.7213883650930304 |Validation acc: 0.5488721804511278, Validation loss: 1.6256275177001953\n",
            "Epoch 30: Train acc: 0.5781119465329991, Train loss: 1.7125161823473478 |Validation acc: 0.5639097744360902, Validation loss: 1.6172800064086914\n",
            "Epoch 31: Train acc: 0.5873015873015873, Train loss: 1.7039594148334705 |Validation acc: 0.5701754385964912, Validation loss: 1.6098530633108956\n",
            "Epoch 32: Train acc: 0.5948203842940685, Train loss: 1.6957550048828125 |Validation acc: 0.5789473684210527, Validation loss: 1.6021432876586914\n",
            "Epoch 33: Train acc: 0.5998329156223893, Train loss: 1.6882205762361224 |Validation acc: 0.5877192982456141, Validation loss: 1.5953786032540458\n",
            "Epoch 34: Train acc: 0.6056808688387636, Train loss: 1.680463288959704 |Validation acc: 0.5914786967418546, Validation loss: 1.588829449244908\n",
            "Epoch 35: Train acc: 0.6111111111111112, Train loss: 1.673430794163754 |Validation acc: 0.5889724310776943, Validation loss: 1.5821499143327986\n",
            "Epoch 36: Train acc: 0.6157059314954052, Train loss: 1.6669785348992598 |Validation acc: 0.5952380952380952, Validation loss: 1.576425552368164\n",
            "Epoch 37: Train acc: 0.6194653299916458, Train loss: 1.6599682255795127 |Validation acc: 0.5989974937343359, Validation loss: 1.5702650887625558\n",
            "Epoch 38: Train acc: 0.6265664160401002, Train loss: 1.654385717291581 |Validation acc: 0.600250626566416, Validation loss: 1.565164429800851\n",
            "Epoch 39: Train acc: 0.6340852130325815, Train loss: 1.6476361124139083 |Validation acc: 0.6040100250626567, Validation loss: 1.5594729014805384\n",
            "Epoch 40: Train acc: 0.6390977443609023, Train loss: 1.6425276304546155 |Validation acc: 0.6090225563909775, Validation loss: 1.5547088895525252\n",
            "Epoch 41: Train acc: 0.6449456975772765, Train loss: 1.6359738801655017 |Validation acc: 0.6152882205513784, Validation loss: 1.5495010103498186\n",
            "Epoch 42: Train acc: 0.650375939849624, Train loss: 1.6313003740812604 |Validation acc: 0.6203007518796992, Validation loss: 1.545133181980678\n",
            "Epoch 43: Train acc: 0.6553884711779449, Train loss: 1.6248919838353206 |Validation acc: 0.6228070175438597, Validation loss: 1.5402684892926897\n",
            "Epoch 44: Train acc: 0.6620718462823726, Train loss: 1.6204483634547184 |Validation acc: 0.6340852130325815, Validation loss: 1.5361826760428292\n",
            "Epoch 45: Train acc: 0.6641604010025063, Train loss: 1.6144471419484991 |Validation acc: 0.6365914786967418, Validation loss: 1.5318235669817244\n",
            "Epoch 46: Train acc: 0.677109440267335, Train loss: 1.6099455984015214 |Validation acc: 0.6466165413533834, Validation loss: 1.5278919764927454\n",
            "Epoch 47: Train acc: 0.6804511278195489, Train loss: 1.6045791224429482 |Validation acc: 0.6528822055137845, Validation loss: 1.5240737370082311\n",
            "Epoch 48: Train acc: 0.6871345029239766, Train loss: 1.5998296235737048 |Validation acc: 0.656641604010025, Validation loss: 1.520303726196289\n",
            "Epoch 49: Train acc: 0.6888053467000835, Train loss: 1.5950170818128084 |Validation acc: 0.6604010025062657, Validation loss: 1.516822133745466\n",
            "Epoch 50: Train acc: 0.6946532999164579, Train loss: 1.590239073100843 |Validation acc: 0.6691729323308271, Validation loss: 1.5132545743669783\n",
            "Epoch 51: Train acc: 0.6963241436925648, Train loss: 1.5858068968120373 |Validation acc: 0.6716791979949874, Validation loss: 1.5100272042410714\n",
            "Epoch 52: Train acc: 0.7038429406850459, Train loss: 1.5811060855263157 |Validation acc: 0.6779448621553885, Validation loss: 1.5067610059465681\n",
            "Epoch 53: Train acc: 0.7059314954051796, Train loss: 1.5769438492624384 |Validation acc: 0.6779448621553885, Validation loss: 1.503680637904576\n",
            "Epoch 54: Train acc: 0.7113617376775272, Train loss: 1.5723337876169305 |Validation acc: 0.6867167919799498, Validation loss: 1.5005959102085658\n",
            "Epoch 55: Train acc: 0.7159565580618212, Train loss: 1.5682274667840255 |Validation acc: 0.6892230576441103, Validation loss: 1.4977027348109655\n",
            "Epoch 56: Train acc: 0.7201336675020885, Train loss: 1.5639204727975946 |Validation acc: 0.6942355889724311, Validation loss: 1.4948419843401228\n",
            "Epoch 57: Train acc: 0.722639933166249, Train loss: 1.5597809239437705 |Validation acc: 0.6954887218045113, Validation loss: 1.492063249860491\n",
            "Epoch 58: Train acc: 0.7268170426065163, Train loss: 1.5557797080592106 |Validation acc: 0.6992481203007519, Validation loss: 1.489356858389718\n",
            "Epoch 59: Train acc: 0.7297410192147035, Train loss: 1.5516956730892784 |Validation acc: 0.7030075187969925, Validation loss: 1.486731801714216\n",
            "Epoch 60: Train acc: 0.7330827067669173, Train loss: 1.5476958626195003 |Validation acc: 0.7030075187969925, Validation loss: 1.4841132845197404\n",
            "Epoch 61: Train acc: 0.7351712614870509, Train loss: 1.544004942241468 |Validation acc: 0.7092731829573935, Validation loss: 1.481644630432129\n",
            "Epoch 62: Train acc: 0.7389306599832915, Train loss: 1.5399483128597862 |Validation acc: 0.7105263157894737, Validation loss: 1.479179518563407\n",
            "Epoch 63: Train acc: 0.7418546365914787, Train loss: 1.536245346069336 |Validation acc: 0.7155388471177945, Validation loss: 1.4766110011509486\n",
            "Epoch 64: Train acc: 0.7451963241436925, Train loss: 1.532570286800987 |Validation acc: 0.7167919799498746, Validation loss: 1.4743449347359794\n",
            "Epoch 65: Train acc: 0.7481203007518797, Train loss: 1.5287279831735712 |Validation acc: 0.7192982456140351, Validation loss: 1.4718216487339564\n",
            "Epoch 66: Train acc: 0.7531328320802005, Train loss: 1.5253882157175165 |Validation acc: 0.7218045112781954, Validation loss: 1.4696934563773019\n",
            "Epoch 67: Train acc: 0.7560568086883876, Train loss: 1.5214818653307463 |Validation acc: 0.7268170426065163, Validation loss: 1.4672534125191825\n",
            "Epoch 68: Train acc: 0.758563074352548, Train loss: 1.5181961059570312 |Validation acc: 0.7255639097744361, Validation loss: 1.465212004525321\n",
            "Epoch 69: Train acc: 0.7610693400167085, Train loss: 1.5144374245091488 |Validation acc: 0.7255639097744361, Validation loss: 1.46292359488351\n",
            "Epoch 70: Train acc: 0.7631578947368421, Train loss: 1.5111670243112665 |Validation acc: 0.7293233082706767, Validation loss: 1.4609417234148299\n",
            "Epoch 71: Train acc: 0.7660818713450293, Train loss: 1.5075292085346423 |Validation acc: 0.7293233082706767, Validation loss: 1.4587657111031669\n",
            "Epoch 72: Train acc: 0.7706766917293233, Train loss: 1.5043539749948602 |Validation acc: 0.7305764411027569, Validation loss: 1.4568444660731725\n",
            "Epoch 73: Train acc: 0.7719298245614035, Train loss: 1.5008255807976973 |Validation acc: 0.7305764411027569, Validation loss: 1.4547120503016882\n",
            "Epoch 74: Train acc: 0.7736006683375104, Train loss: 1.497642717863384 |Validation acc: 0.7305764411027569, Validation loss: 1.45278685433524\n",
            "Epoch 75: Train acc: 0.7752715121136173, Train loss: 1.4942011582223993 |Validation acc: 0.731829573934837, Validation loss: 1.4507594789777483\n",
            "Epoch 76: Train acc: 0.777360066833751, Train loss: 1.4910592530903064 |Validation acc: 0.7368421052631579, Validation loss: 1.4488367353166853\n",
            "Epoch 77: Train acc: 0.779030910609858, Train loss: 1.4878048143888776 |Validation acc: 0.7380952380952381, Validation loss: 1.4469330651419503\n",
            "Epoch 78: Train acc: 0.7832080200501254, Train loss: 1.484598159790039 |Validation acc: 0.7380952380952381, Validation loss: 1.4450460161481584\n",
            "Epoch 79: Train acc: 0.7848788638262323, Train loss: 1.4814825559917248 |Validation acc: 0.7380952380952381, Validation loss: 1.443214280264718\n",
            "Epoch 80: Train acc: 0.7882205513784462, Train loss: 1.47837317617316 |Validation acc: 0.7406015037593985, Validation loss: 1.4414314542497908\n",
            "Epoch 81: Train acc: 0.7894736842105263, Train loss: 1.47526720950478 |Validation acc: 0.7431077694235589, Validation loss: 1.439552170889718\n",
            "Epoch 82: Train acc: 0.7919799498746867, Train loss: 1.4721657602410567 |Validation acc: 0.7418546365914787, Validation loss: 1.4378114427839006\n",
            "Epoch 83: Train acc: 0.7936507936507936, Train loss: 1.4691979257684005 |Validation acc: 0.7431077694235589, Validation loss: 1.4360104969569616\n",
            "Epoch 84: Train acc: 0.7957393483709273, Train loss: 1.466204191509046 |Validation acc: 0.7431077694235589, Validation loss: 1.434410640171596\n",
            "Epoch 85: Train acc: 0.797827903091061, Train loss: 1.4631469124241878 |Validation acc: 0.7443609022556391, Validation loss: 1.432523454938616\n",
            "Epoch 86: Train acc: 0.7982456140350878, Train loss: 1.460207085860403 |Validation acc: 0.7456140350877193, Validation loss: 1.4308523450578963\n",
            "Epoch 87: Train acc: 0.8003341687552213, Train loss: 1.4572932594700863 |Validation acc: 0.7456140350877193, Validation loss: 1.4290849140712194\n",
            "Epoch 88: Train acc: 0.8007518796992481, Train loss: 1.4542320653011924 |Validation acc: 0.7481203007518797, Validation loss: 1.4273323331560408\n",
            "Epoch 89: Train acc: 0.8032581453634086, Train loss: 1.4516332525956004 |Validation acc: 0.7481203007518797, Validation loss: 1.4257146290370397\n",
            "Epoch 90: Train acc: 0.8049289891395155, Train loss: 1.4484095322458368 |Validation acc: 0.7518796992481203, Validation loss: 1.4239352090018136\n",
            "Epoch 91: Train acc: 0.808688387635756, Train loss: 1.4457338232743113 |Validation acc: 0.7556390977443609, Validation loss: 1.4222662789481026\n",
            "Epoch 92: Train acc: 0.8128654970760234, Train loss: 1.4427317569130345 |Validation acc: 0.7568922305764411, Validation loss: 1.4205938066755022\n",
            "Epoch 93: Train acc: 0.8153717627401837, Train loss: 1.4400178005820827 |Validation acc: 0.7631578947368421, Validation loss: 1.4188464028494698\n",
            "Epoch 94: Train acc: 0.8170426065162907, Train loss: 1.4370660279926502 |Validation acc: 0.7644110275689223, Validation loss: 1.417217527117048\n",
            "Epoch 95: Train acc: 0.8195488721804511, Train loss: 1.4343571913869757 |Validation acc: 0.7644110275689223, Validation loss: 1.415405000959124\n",
            "Epoch 96: Train acc: 0.8220551378446115, Train loss: 1.4315249794407894 |Validation acc: 0.7669172932330827, Validation loss: 1.4137817110334123\n",
            "Epoch 97: Train acc: 0.8249791144527987, Train loss: 1.4288042971962376 |Validation acc: 0.768170426065163, Validation loss: 1.4120502471923828\n",
            "Epoch 98: Train acc: 0.8279030910609858, Train loss: 1.4260391436125104 |Validation acc: 0.7669172932330827, Validation loss: 1.4104727336338587\n",
            "Epoch 99: Train acc: 0.8304093567251462, Train loss: 1.4233626315468235 |Validation acc: 0.768170426065163, Validation loss: 1.4086508069719588\n",
            "Epoch 100: Train acc: 0.8320802005012531, Train loss: 1.4206137406198602 |Validation acc: 0.7719298245614035, Validation loss: 1.4070986339024134\n",
            "Epoch 101: Train acc: 0.8350041771094403, Train loss: 1.418033198306435 |Validation acc: 0.7756892230576441, Validation loss: 1.4053995949881417\n",
            "Epoch 102: Train acc: 0.8391812865497076, Train loss: 1.4152963537918894 |Validation acc: 0.7781954887218046, Validation loss: 1.4037562779017858\n",
            "Epoch 103: Train acc: 0.8404344193817878, Train loss: 1.4128024452611019 |Validation acc: 0.7807017543859649, Validation loss: 1.4021173204694475\n",
            "Epoch 104: Train acc: 0.8429406850459482, Train loss: 1.4100490369294818 |Validation acc: 0.7819548872180451, Validation loss: 1.400416374206543\n",
            "Epoch 105: Train acc: 0.8467000835421888, Train loss: 1.407634132786801 |Validation acc: 0.7819548872180451, Validation loss: 1.398892947605678\n",
            "Epoch 106: Train acc: 0.847953216374269, Train loss: 1.4049073269492702 |Validation acc: 0.7832080200501254, Validation loss: 1.397308349609375\n",
            "Epoch 107: Train acc: 0.849624060150376, Train loss: 1.4023943449321545 |Validation acc: 0.7844611528822055, Validation loss: 1.3957007271902901\n",
            "Epoch 108: Train acc: 0.8504594820384294, Train loss: 1.3999126835873252 |Validation acc: 0.7832080200501254, Validation loss: 1.3941586358206612\n",
            "Epoch 109: Train acc: 0.852548036758563, Train loss: 1.3973439869127775 |Validation acc: 0.7882205513784462, Validation loss: 1.3925822121756417\n",
            "Epoch 110: Train acc: 0.8529657477025898, Train loss: 1.3948767812628495 |Validation acc: 0.7894736842105263, Validation loss: 1.391162736075265\n",
            "Epoch 111: Train acc: 0.8550543024227235, Train loss: 1.3924621782804791 |Validation acc: 0.7919799498746867, Validation loss: 1.3896356310163225\n",
            "Epoch 112: Train acc: 0.8575605680868839, Train loss: 1.3899864397550885 |Validation acc: 0.7907268170426065, Validation loss: 1.388242312840053\n",
            "Epoch 113: Train acc: 0.8592314118629908, Train loss: 1.3875554737291838 |Validation acc: 0.7919799498746867, Validation loss: 1.3867348262241908\n",
            "Epoch 114: Train acc: 0.860484544695071, Train loss: 1.3851409711335834 |Validation acc: 0.793233082706767, Validation loss: 1.3854058129446847\n",
            "Epoch 115: Train acc: 0.8621553884711779, Train loss: 1.3828407086824115 |Validation acc: 0.7969924812030075, Validation loss: 1.3839802060808455\n",
            "Epoch 116: Train acc: 0.8638262322472848, Train loss: 1.380493866769891 |Validation acc: 0.7969924812030075, Validation loss: 1.3826750346592493\n",
            "Epoch 117: Train acc: 0.8650793650793651, Train loss: 1.3781967163085938 |Validation acc: 0.7982456140350878, Validation loss: 1.3812968390328544\n",
            "Epoch 118: Train acc: 0.8659147869674185, Train loss: 1.3758740676076788 |Validation acc: 0.7982456140350878, Validation loss: 1.3799992970057897\n",
            "Epoch 119: Train acc: 0.8675856307435255, Train loss: 1.3736474890457957 |Validation acc: 0.8020050125313283, Validation loss: 1.3786942618233817\n",
            "Epoch 120: Train acc: 0.8700918964076859, Train loss: 1.3714337599904913 |Validation acc: 0.8007518796992481, Validation loss: 1.3774948120117188\n",
            "Epoch 121: Train acc: 0.8709273182957393, Train loss: 1.3693029504073293 |Validation acc: 0.8007518796992481, Validation loss: 1.3762224742344447\n",
            "Epoch 122: Train acc: 0.8738512949039264, Train loss: 1.3671667199385793 |Validation acc: 0.8032581453634086, Validation loss: 1.3750580378941126\n",
            "Epoch 123: Train acc: 0.8742690058479532, Train loss: 1.3650181418971012 |Validation acc: 0.8070175438596491, Validation loss: 1.3738603591918945\n",
            "Epoch 124: Train acc: 0.8751044277360067, Train loss: 1.3629297959177118 |Validation acc: 0.8082706766917294, Validation loss: 1.3726763044084822\n",
            "Epoch 125: Train acc: 0.8755221386800334, Train loss: 1.3609019831607216 |Validation acc: 0.8082706766917294, Validation loss: 1.3715358461652483\n",
            "Epoch 126: Train acc: 0.8771929824561403, Train loss: 1.3588192588404606 |Validation acc: 0.8107769423558897, Validation loss: 1.3703245435442244\n",
            "Epoch 127: Train acc: 0.879281537176274, Train loss: 1.3568098168624074 |Validation acc: 0.8107769423558897, Validation loss: 1.369286400931222\n",
            "Epoch 128: Train acc: 0.8796992481203008, Train loss: 1.354922746357165 |Validation acc: 0.8107769423558897, Validation loss: 1.3681037085396903\n",
            "Epoch 129: Train acc: 0.8801169590643275, Train loss: 1.3529342852140729 |Validation acc: 0.8120300751879699, Validation loss: 1.3670662471226283\n",
            "Epoch 130: Train acc: 0.8813700918964077, Train loss: 1.3510686974776418 |Validation acc: 0.8120300751879699, Validation loss: 1.366002082824707\n",
            "Epoch 131: Train acc: 0.8817878028404345, Train loss: 1.3492212797466077 |Validation acc: 0.8120300751879699, Validation loss: 1.3649571282523019\n",
            "Epoch 132: Train acc: 0.8826232247284879, Train loss: 1.3473023866352283 |Validation acc: 0.8132832080200502, Validation loss: 1.3639060429164342\n",
            "Epoch 133: Train acc: 0.8830409356725146, Train loss: 1.3456782290810032 |Validation acc: 0.8132832080200502, Validation loss: 1.362907954624721\n",
            "Epoch 134: Train acc: 0.8834586466165414, Train loss: 1.343745884142424 |Validation acc: 0.8132832080200502, Validation loss: 1.3618594578334264\n",
            "Epoch 135: Train acc: 0.8842940685045948, Train loss: 1.3421982213070518 |Validation acc: 0.8145363408521303, Validation loss: 1.360909870692662\n",
            "Epoch 136: Train acc: 0.8868003341687553, Train loss: 1.3402711968672902 |Validation acc: 0.8170426065162907, Validation loss: 1.3599014282226562\n",
            "Epoch 137: Train acc: 0.8876357560568087, Train loss: 1.3387263448614823 |Validation acc: 0.8195488721804511, Validation loss: 1.3589616503034319\n",
            "Epoch 138: Train acc: 0.8880534670008354, Train loss: 1.3369857386538857 |Validation acc: 0.8195488721804511, Validation loss: 1.3579765047345842\n",
            "Epoch 139: Train acc: 0.8884711779448622, Train loss: 1.335383465415553 |Validation acc: 0.8220551378446115, Validation loss: 1.3570605686732702\n",
            "Epoch 140: Train acc: 0.8888888888888888, Train loss: 1.3336671528063322 |Validation acc: 0.8208020050125313, Validation loss: 1.3560846873692103\n",
            "Epoch 141: Train acc: 0.8901420217209691, Train loss: 1.3321717914782072 |Validation acc: 0.8233082706766918, Validation loss: 1.3552014487130302\n",
            "Epoch 142: Train acc: 0.8909774436090225, Train loss: 1.3305389002749795 |Validation acc: 0.8233082706766918, Validation loss: 1.3542687552315849\n",
            "Epoch 143: Train acc: 0.8913951545530493, Train loss: 1.3289268895199424 |Validation acc: 0.8245614035087719, Validation loss: 1.353334971836635\n",
            "Epoch 144: Train acc: 0.8918128654970761, Train loss: 1.327417674817537 |Validation acc: 0.8258145363408521, Validation loss: 1.3524188995361328\n",
            "Epoch 145: Train acc: 0.8922305764411027, Train loss: 1.3259368695710834 |Validation acc: 0.8258145363408521, Validation loss: 1.3514998299734933\n",
            "Epoch 146: Train acc: 0.893483709273183, Train loss: 1.3244139018811678 |Validation acc: 0.8270676691729323, Validation loss: 1.3506596429007394\n",
            "Epoch 147: Train acc: 0.8939014202172096, Train loss: 1.3229685331645764 |Validation acc: 0.8283208020050126, Validation loss: 1.3497205461774553\n",
            "Epoch 148: Train acc: 0.8943191311612364, Train loss: 1.3215027859336452 |Validation acc: 0.8283208020050126, Validation loss: 1.3489193235124861\n",
            "Epoch 149: Train acc: 0.8955722639933166, Train loss: 1.3201475645366467 |Validation acc: 0.8308270676691729, Validation loss: 1.3480253219604492\n",
            "Epoch 150: Train acc: 0.8955722639933166, Train loss: 1.3186256007144326 |Validation acc: 0.8320802005012531, Validation loss: 1.3471407209123885\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBO79gZH4StT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "e1e7e174-f45b-4201-b8ba-5336dd8a7a55"
      },
      "source": [
        "model_path = get_model_name(\"alexnet_ann\", batch_size=128, learning_rate=0.001, epoch=149)\n",
        "plot_training_curve('/content/' + model_path)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Final Training Accuracy: 0.8955722639933166\n",
            "Final Validation Accuracy: 0.8320802005012531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZANRBIiYd2F_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a80ec802-1980-4e8d-efa5-71a3e388e199"
      },
      "source": [
        "model = ANNClassifier_Alexnet()\n",
        "model_path = get_model_name(\"alexnet_ann\", batch_size=128, learning_rate=0.001, epoch=149)\n",
        "\n",
        "state = torch.load('/content/' + model_path)\n",
        "model.load_state_dict(state)\n",
        "\n",
        "data_dir='/content/drive/My Drive/Colab Notebooks/Faces/alexnet'\n",
        "\n",
        "train_loader, val_loader, test_loader = get_features_data_loader(data_dir=data_dir, batch_size=128)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "test_acc, test_loss = evaluate(model, test_loader, criterion)\n",
        "print(\"Test classification accuracy:\", test_acc)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:67: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test classification accuracy: 0.8329081632653061\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}